{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 (4 points): 1D CNN [Pen and Paper]\n",
    "\n",
    "In this assignment, we want to understand convolutional neural networks (CNNs) and we start by applying them to a one-dimensional input so that we get used to the basic concepts. An implementation applied to images follows in Exercise 2.\n",
    "\n",
    "In the context of this exercise, the output ğ‘¦ğ‘˜ of the ğ‘˜-th neuron in the ğ‘—-th feature map of a convolutional layer is calculated as <br/>\n",
    "\n",
    "\\begin{equation}y_{k,j} = f \\left(\\sum_{i=1}^M \\sum_{c=1}^C w_{i, c; j}â‹… x_{i+k-1, c} + b_j\\right)\\end{equation}\n",
    "\n",
    "with the weights ğ‘¤ğ‘–,ğ‘;ğ‘—, the input ğ‘¥ğ‘–,ğ‘, the bias ğ‘ğ‘— and the transfer function ğ‘“ (ğ‘¥). ğ‘€ denotes the filter length and ğ¶ the number of channels this filter pools from. Note: Equation 1 does not include the concepts of padding and stride sizes used below (cf. TensorFlow references for further details about these parameters).\n",
    "\n",
    "Suppose that our CNN is defined as follows:\n",
    "    \n",
    "    I An input of length 10 consisting of ğ¶ = 2 channels.\n",
    "    \n",
    "    II One convolutional layer with 3 feature maps, a filter length of ğ‘€ = 5, a stride of 1 and the padding set to valid. As activation function, rectified linear units, i.e. ğ‘“ (ğ‘¥) = max(ğ‘¥, 0), are used.\n",
    "    \n",
    "    III A max-pooling layer with a pool size of 3, a stride of 2 and the padding set to same.\n",
    "    \n",
    "    IV Two output neurons with a linear activation function (the output of the pooling layer is flattened before it is passed on to the output layer).\n",
    "    \n",
    "Letâ€™s use this network to perform some basic computations.\n",
    "1. The upper part of the input matrix ğ‘‹ is given as follows\n",
    "\\begin{pmatrix}\n",
    "x_{1, 1} & 0\\\\\n",
    "1 & -1\\\\\n",
    "2 & 0\\\\\n",
    "0 & 0\\\\\n",
    "1 & 1\\\\\n",
    "\\vdots & \\vdots\n",
    "\\end{pmatrix}\n",
    "We now consider the first filter (ğ‘— = 1) of the convolutional layer.\n",
    "    \n",
    "    a) What is the dimension of the weight matrix ğ‘Š (filter size)?\n",
    "\n",
    "    b) Suppose that all weights which pool from the first channel are set to $w_{i,1;1} = 1$, the weights for the second channel are set to $w_{i,2;1} = 2$ and the bias is set to $b_1 = 0$. The output of the first neuron is $y_{1;1} = 5$. Calculate the missing input value $x_{1,1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What is the difference between a one-dimensional convolutional layer (temporal convolution) which pools from multiple channels (as implemented by Equation 1) compared to a two-dimensional CNN layer (e.g. with a filter size of 5 Ã— 2)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. For each layer in our network, fill out Table 1 by deciding about\n",
    "\n",
    "    â€¢ the dimensions of the layerâ€™s output tensor (e.g. output matrix of the convolutional layer).\n",
    "\n",
    "    â€¢ the number of weights per layer (if any).\n",
    "\n",
    "    â€¢ the number of biases per layer (if any)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Suppose we used a standard hidden layer with 10 neurons instead of the convolutional and pooling layers (the output neurons are still used), how does the total number of weights and biases in the network change (the input is flattened before it is passed on to the hidden layer)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 (6 points): 2D CNN\n",
    "\n",
    "The convolution operation is often used in computer vision domain and it is hence not surprising that CNNs are especially helpful in image processing tasks. We now want to apply a CNN to a small image classification task based on the STL-10 dataset [1]. More concretely, we are using two classes with 500 images each and train a network to distinguish between them.\n",
    "\n",
    "Our main goal is to visualize how the network processes the images, i.e. highlight the activations of the layers. Therefore, we disregard other aspects like the validation against a test set. Further, we are also going to cover some new TensorFlow aspects, namely datasets and iterators2 as a novel way to feed data to the network.\n",
    "\n",
    "Please use the file CNN2D.ipynb attached to this exercise as the basis for your implementation. For the test script, please pay also attention to Table 2.\n",
    "\n",
    "1. Load the images and the corresponding labels from the attached stl10.pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. It would not be very practical to visualize the network activations for all images so we only use a few examples. Create a subset of the images (and labels) which contains these example images. Make sure that you use at least one instance per class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We need to feed the images and the corresponding labels to the network and we want to use datasets and iterators for this purpose.\n",
    "\n",
    "    a) Define a training dataset which iterates over all images. Shuffle the dataset (set a buffer size which equals the total number of training instances) and then apply the specified batch size.\n",
    "\n",
    "    b) Define another dataset for the example images selected previously. Batch over all instances at once.\n",
    "\n",
    "    c) Create a reinitializable iterator and define an initialization operation for each dataset.\n",
    "\n",
    "    d) To access the data, extract tensors for the images and labels from the iterator (iter ator.get_next())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. We now have all ingredients together to build our network. Use the defined parameters whenever it is suitable.\n",
    "\n",
    "    a) Create a hierarchy of subsequent convolutional and pooling layer pairs (n_cnn_la yers in total). That is, first process the input via a (two-dimensional) convolutional layer and then apply an average (two-dimensional) polling layer. Store the CNN layers so that you can later easily calculate the network activations for the example images.\n",
    "\n",
    "    b) Reshape the output of the last pooling layer to a one-dimensional vector. Note that you still need a two-dimensional tensor with the first dimension denoting the batches.\n",
    "\n",
    "    c) Use a final (linear) layer which calculates the logits for each class. \n",
    "    \n",
    "    d) Define a training operation based on the cross-entropy loss function (including regularization) and the Adam optimizer.\n",
    "\n",
    "    e) Create a tensor which calculates the accuracy over the current batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. The next step is to train and evaluate the network. We also want to calculate (and store) the activation images whenever the state of the network changes. Note that the training can take a few minutes.\n",
    "\n",
    "    a) Calculate the activation images for the initial state of the network (after initializing the variables).\n",
    "\n",
    "    b) Train the network over multiple epochs. With each training step (one batch), calculate the loss and the accuracy and average all values together so that one loss and one accuracy value per epoch remains3. Keep track of these values.\n",
    "\n",
    "    c) After the training phase of each epoch, calculate the activation images again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Plot the loss and the accuracy values over the epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Plot your selected images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Create an animation (interact) for the activation images which lets you select the image, the epoch and the layer. For each configuration, the output of the four filters should be shown. Set explicit values for the data range when using the imshow() function (vmin and vmax) which correspond to the boundaries of the tanh(ğ‘¥) function. An example can be seen in Figure 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
