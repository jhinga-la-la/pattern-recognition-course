{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 (3 points): Decision Surfaces via Gaussian Density Functions [Pen and Paper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Bayes classification process, we try to find decision surfaces which separate the classes in the feature domain. These surfaces define a region for each class so that new data points can easily be assigned to one of the classes. In this exercise, we want to analyse different decision surfaces based on multivariate Gaussian densities. \n",
    "<br />\n",
    "<br />\n",
    "We operate in the two-dimensional feature space and use a two-class problem, i.e. a point 𝑥 ∈ ℝ<sup>2</sup> is either assigned to the class 𝜔<sub>1</sub> or the class 𝜔<sub>2</sub>. With the Bayes rule, the resulting surface is defined by the corresponding posterior probabilities of the two classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(\\omega_1|x) = P(\\omega_2|x) $$\n",
    "<br />\n",
    "$$ \\frac{p(x|\\omega_1) ⋅ P(\\omega_1)}{p(x)} = \\frac{p(x|\\omega_2) ⋅ P(\\omega_2)}{p(x)} $$\n",
    "<br />\n",
    "$$ p(x|\\omega_1) ⋅ P(\\omega_1) = p(x|\\omega_2) ⋅ P(\\omega_2) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and reduces to the likelihoods 𝑝(𝑥|𝜔<sub>𝑖</sub>) and prior-probabilities 𝑃(𝜔<sub>𝑖</sub>). For the sake of simplicity, we assume equiprobable classes (𝑃(𝜔<sub>1</sub>) = 𝑃(𝜔<sub>2</sub>) = 0.5) so that the decision is solely based on the Gaussian density functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ p(x|\\omega_i) = \\frac{1}{(2\\pi)^{d/2}|\\sum_i|^{1/2}} exp \\left(−\\frac{1}{2}(x − \\mu_i)^T {\\sum_i}^{-1} (x − \\mu_i)\\right) $$\n",
    "<br/>\n",
    "with the mean vector 𝜇<sub>𝑖</sub> and the covariance matrix 𝛴<sub>𝑖</sub> for each class 𝑖."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1 shows three different decision surfaces as well as either a corresponding 𝑥<sub>1</sub>- or 𝑥<sub>2</sub>-slice. Table 1 summarizes the parameters used to create the figures. Note that we have two Gaussian functions in each case (one for each class). Your task is to map each line in Table 1 to the corresponding decision surface and slice. Please explain your choices, e.g. via sketches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 (7 points): Euclidean Distance, Standardization, Mahalanobis Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many applications, it is helpful when we deal with homogeneous data. This is especially\n",
    "important when points should be compared in one way or another. Here, we want to measure\n",
    "the similarity between two points by calculating the corresponding distance. We start with the\n",
    "Euclidean distance, move forward to standardized variables and end up with the Mahalanobis\n",
    "distance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
